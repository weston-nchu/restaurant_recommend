# -*- coding: utf-8 -*-
"""DQN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cNQEzlXSxL2fSrJbrLX9CShjXiQNpXGJ

start()
train(liked_restaurant_name_slugs: list)
get_recommendations_json(selected_tags_for_user_profile_short)
"""
import pandas as pd
import numpy as np
import random
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense, Input
from keras.optimizers import Adam
from collections import deque
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
from sklearn.neighbors import NearestNeighbors # For KNN
import os # For file operations
import json # For JSON output

# --- Global Constants ---
# Keeping tags in English as previously specified for internal processing
TAG_COLUMN_MAP = {
    '種類_中': 'Chinese', '種類_日': 'Japanese', '種類_法': 'French', '種類_泰': 'Thai',
    '種類_美': 'American', '種類_西': 'Western', '種類_韓': 'Korean',
    '類型_咖啡': 'Coffee Shop', '類型_地方': 'Local Cuisine', '類型_小吃': 'Snack Bar', '類型_居酒': 'Izakaya',
    '類型_火鍋': 'Hot Pot', '類型_甜點': 'Dessert', '類型_聚餐': 'Gathering Place', '類型_茶館': 'Tea House',
    '類型_酒吧': 'Bar', '類型_餐酒': 'Bistro',
    '氛圍_安靜': 'Quiet Atmosphere', '氛圍_家庭': 'Family Friendly', '氛圍_時尚': 'Fashionable',
    '氛圍_浪漫': 'Romantic', '氛圍_熱鬧': 'Lively', '氛圍_約會': 'Dating Spot',
    '氛圍_聚餐': 'Group Meal Friendly', '氛圍_舒適': 'Cozy Atmosphere'
}

ALL_POSSIBLE_TAGS = sorted(list(TAG_COLUMN_MAP.values())) # Used for DQN state vector
TAG_TO_INDEX = {tag: i for i, tag in enumerate(ALL_POSSIBLE_TAGS)} # For DQN state
INDEX_TO_TAG = {i: tag for tag, i in TAG_TO_INDEX.items()} # For DQN state
NUM_TAGS_DQN = len(ALL_POSSIBLE_TAGS) # For DQN state size

# --- Global Variables for State Management ---
global_df_aa = None
global_agent = None
global_aa_csv_tag_bool_columns = None
global_aa_csv_ordered_readable_tags = None
global_restaurant_features_knn = None
global_shown_in_session_urls = set() # To keep track of restaurants shown across calls
global_all_experiences_for_buffer = [] # Accumulate experiences here
global_current_round_options = [] # Store the options from the last `start()` call for lookup

# --- Helper Functions ---
def get_restaurant_tags_set(restaurant_row):
    """
    Extracts a set of readable tags from a restaurant row based on boolean columns.
    """
    tags = set()
    for col, readable_tag in TAG_COLUMN_MAP.items():
        if col in restaurant_row and restaurant_row[col] == True:
            tags.add(readable_tag)
    return tags

def tags_to_multihot_dqn(tags_set):
    """
    Converts a set of readable tags into a multi-hot encoded vector
    for the DQN state, based on ALL_POSSIBLE_TAGS's order.
    """
    multihot = np.zeros(NUM_TAGS_DQN)
    for tag in tags_set:
        if tag in TAG_TO_INDEX:
            multihot[TAG_TO_INDEX[tag]] = 1
    return multihot

# --- 1. Load and Prepare Data Function ---
def load_and_prepare_data(file_path):
    """
    Loads restaurant data, processes tags, and prepares feature vectors.

    Args:
        file_path (str): Path to the restaurant CSV file.

    Returns:
        tuple: (df_aa, aa_csv_tag_bool_columns, aa_csv_ordered_readable_tags, restaurant_features_knn)
                df_aa (pd.DataFrame): Loaded and processed DataFrame.
                aa_csv_tag_bool_columns (list): List of boolean tag column names.
                aa_csv_ordered_readable_tags (list): List of readable tag names in the same order.
                restaurant_features_knn (np.ndarray): Feature array for KNN/K-Means.
    """
    try:
        df_aa = pd.read_csv(file_path)
    except FileNotFoundError:
        print(f"Error: '{file_path}' not found. Make sure the file is in the same directory.")
        exit()

    aa_csv_tag_bool_columns = [col for col in TAG_COLUMN_MAP.keys() if col in df_aa.columns]
    aa_csv_ordered_readable_tags = [TAG_COLUMN_MAP[col] for col in aa_csv_tag_bool_columns]

    df_aa['tags_set'] = df_aa.apply(get_restaurant_tags_set, axis=1)

    restaurant_features_knn = df_aa[aa_csv_tag_bool_columns].fillna(False).astype(float).values

    print(f"Loaded data from '{file_path}'. Found {len(df_aa)} restaurants.")
    return df_aa, aa_csv_tag_bool_columns, aa_csv_ordered_readable_tags, restaurant_features_knn

# --- 2. K-Means Clustering Function ---
def perform_kmeans_clustering(df_aa, restaurant_features_knn, num_clusters_param):
    """
    Performs K-Means clustering on restaurant features and assigns clusters to the DataFrame.
    """
    num_clusters_actual = num_clusters_param
    if len(df_aa) < num_clusters_actual:
        num_clusters_actual = max(1, len(df_aa))

    kmeans = KMeans(n_clusters=num_clusters_actual, n_init=10)
    if restaurant_features_knn.shape[0] > 0 and restaurant_features_knn.shape[1] > 0:
        df_aa['cluster'] = kmeans.fit_predict(restaurant_features_knn)
        print(f"Restaurants clustered into {num_clusters_actual} groups for interaction.")
    else:
        print("No features to cluster for interaction. Assigning default cluster.")
        df_aa['cluster'] = 0
    return df_aa

# --- DQN Agent Class ---
class DQNAgent:
    """
    Deep Q-Network (DQN) Agent for learning restaurant preferences.
    """
    def __init__(self, state_size, action_size=1):
        self.state_size = state_size
        self.action_size = action_size
        self.replay_buffer = deque(maxlen=5000)
        self.gamma = 0.95
        self.learning_rate = 0.001
        self.model = self._build_model()

    def _build_model(self):
        """Builds the Keras neural network model."""
        model = Sequential()
        model.add(Input(shape=(self.state_size,)))
        model.add(Dense(64, activation='relu', name='dense_1'))
        model.add(Dense(32, activation='relu', name='dense_2'))
        model.add(Dense(self.action_size, activation='linear', name='output_q'))
        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))
        return model

    def remember(self, state, reward):
        """Stores an experience in the replay buffer."""
        self.replay_buffer.append((state, reward))

    def replay_and_train(self, batch_size, epochs):
        """Trains the DQN model using experiences from the replay buffer."""
        if len(self.replay_buffer) < batch_size:
            print(f"Not enough samples in replay buffer ({len(self.replay_buffer)}) to train with batch size {batch_size}.")
            return []
        all_states = np.array([transition[0] for transition in self.replay_buffer])
        all_rewards = np.array([transition[1] for transition in self.replay_buffer])
        history = self.model.fit(all_states, all_rewards, epochs=epochs, batch_size=batch_size, verbose=0, shuffle=True)
        return history.history['loss']

    def get_tag_weights(self):
        """
        Extracts and normalizes the importance weights for each tag from the DQN's first layer.
        Returns a dictionary mapping readable tag names to their normalized weights.
        """
        try:
            first_layer_weights = self.model.get_layer('dense_1').get_weights()[0]
            tag_importance = np.abs(first_layer_weights).sum(axis=1)
            if tag_importance.max() - tag_importance.min() > 0:
                scaler = MinMaxScaler()
                normalized_weights = scaler.fit_transform(tag_importance.reshape(-1, 1)).flatten()
            else:
                normalized_weights = np.zeros_like(tag_importance)
            return {INDEX_TO_TAG[i]: weight for i, weight in enumerate(normalized_weights)}
        except Exception as e:
            print(f"Error getting tag weights: {e}")
            return {tag: 0.0 for tag in ALL_POSSIBLE_TAGS}

    def reset_model_weights(self):
        """Resets the DQN model's weights to initial random values."""
        self.model = self._build_model()

# --- Interaction Functions ---
def get_options_from_clusters_multi(df_source, num_options=10, already_shown_urls_in_session=None):
    """
    Selects a diverse set of restaurants from different clusters for user interaction.
    """
    if already_shown_urls_in_session is None:
        already_shown_urls_in_session = set()

    selected_restaurants = []
    used_clusters = set()

    if 'url' not in df_source.columns: # Ensure 'url' for uniqueness
        df_source['url'] = df_source.index.astype(str) # Use index as URL if not present

    available_df = df_source[~df_source['url'].isin(already_shown_urls_in_session)]
    if available_df.empty:
        # If no new restaurants, allow repetition but prefer those not *just* shown
        available_df = df_source
        if not available_df.empty:
            print("Warning: No new restaurants available, recycling options.")


    cluster_ids = list(available_df['cluster'].unique())
    random.shuffle(cluster_ids)

    # First pass: try to get unique restaurants from unique clusters
    for cluster_id in cluster_ids:
        if len(selected_restaurants) >= num_options:
            break

        current_selected_urls = {r.get('url') for r in selected_restaurants}
        restaurants_in_cluster = available_df[(available_df['cluster'] == cluster_id) & (~available_df['url'].isin(current_selected_urls))]

        if not restaurants_in_cluster.empty:
            chosen = restaurants_in_cluster.sample(1).iloc[0]
            selected_restaurants.append(chosen.to_dict())
            used_clusters.add(cluster_id)

    # Second pass: fill up with any remaining unique restaurants if needed
    num_needed = num_options - len(selected_restaurants)
    if num_needed > 0:
        current_selected_urls_fill = {r.get('url') for r in selected_restaurants}
        potential_fillers_df = available_df[~available_df['url'].isin(current_selected_urls_fill)]

        if not potential_fillers_df.empty:
            additional = potential_fillers_df.sample(min(num_needed, len(potential_fillers_df)), replace=False)
            for _, row in additional.iterrows():
                selected_restaurants.append(row.to_dict())
            num_needed = num_options - len(selected_restaurants)

    # Third pass: if still not enough, allow repetition from anywhere
    if num_needed > 0:
        # If df_source is empty, this would cause an error. Add a check.
        if df_source.empty:
            print("Error: No restaurants available in the dataset.")
            return []

        # Allowing replacement to ensure we can always get the required number
        # even if unique restaurants are fewer than num_options
        fillers_repeated = df_source.sample(num_needed, replace=True)
        for _, row in fillers_repeated.iterrows():
            selected_restaurants.append(row.to_dict())


    return selected_restaurants

def start_interaction_round(df_aa, num_total_options, already_shown_urls):
    """
    Selects restaurant options for a single interaction round based on the new structure.
    It now selects a total of `num_total_options` distinct restaurants
    and then formats them into groups of 3.
    """
    # We need 15 restaurants in total to form 5 groups of 3
    num_restaurants_to_fetch = num_total_options

    options_for_round_full = get_options_from_clusters_multi(
        df_aa, num_options=num_restaurants_to_fetch, already_shown_urls_in_session=already_shown_urls
    )

    if not options_for_round_full:
        print("Not enough diverse restaurants to present for this round.")
        return [], []

    # Update global_shown_in_session_urls with all fetched restaurant URLs
    for opt in options_for_round_full:
        if 'url' in opt and opt['url']:
            already_shown_urls.add(opt['url'])

    # Format into the requested JSON structure: 5 groups of 3 names
    formatted_options = []

    # Ensure we have at least num_total_options items to avoid index errors
    # If not enough unique ones, get_options_from_clusters_multi will have repeated them.
    for i in range(0, num_total_options, 3):
        if i + 2 < len(options_for_round_full): # Ensure we have at least 3 restaurants for this group
            group_entry = {
                "name1": options_for_round_full[i].get('name', 'Unknown-1'),
                "name2": options_for_round_full[i+1].get('name', 'Unknown-2'),
                "name3": options_for_round_full[i+2].get('name', 'Unknown-3'),
            }
            formatted_options.append(group_entry)
        else:
            # Handle cases where the last group might have fewer than 3 elements
            # Or if we couldn't even get 3 restaurants in total
            partial_group = {}
            if i < len(options_for_round_full):
                partial_group["name1"] = options_for_round_full[i].get('name', 'Unknown-1')
            if i + 1 < len(options_for_round_full):
                partial_group["name2"] = options_for_round_full[i+1].get('name', 'Unknown-2')
            if i + 2 < len(options_for_round_full):
                partial_group["name3"] = options_for_round_full[i+2].get('name', 'Unknown-3')
            if partial_group:
                formatted_options.append(partial_group)

    return options_for_round_full, formatted_options # Return both for internal use and external JSON

def process_user_feedback_simplified(agent, options_presented_in_round, liked_name_slugs: list):
    """
    Processes user feedback, rewards, and stores experiences in the agent's replay buffer.
    Assumes `options_presented_in_round` are the exact full restaurant objects shown in the last `start()` call.

    Args:
        agent (DQNAgent): The DQN agent to store experiences.
        options_presented_in_round (list): List of full restaurant dictionaries presented to the user.
        liked_name_slugs (list): List of restaurant name slugs (strings from the 'name' column) that the user liked.
                                  These slugs are expected to be the individual names, not the 'name1', 'name2', 'name3' structure.
    """
    collected_experiences = []
    liked_slugs_set = set(liked_name_slugs)

    if not options_presented_in_round:
        print("No options were presented in the previous round to process feedback for.")
        return []

    # print(f"Processing feedback for options (original names): {[r['restaurant_name'] for r in options_presented_in_round]}")
    print(f"User liked (name slugs provided): {liked_name_slugs}")

    # Iterate through ALL the restaurants that were *actually* selected and presented in the round
    for r_opt in options_presented_in_round:
        # Use the 'name' slug from the original presented option for matching
        restaurant_name_slug = r_opt.get('name')
        if not restaurant_name_slug:
            print(f"Warning: Restaurant option missing 'name' slug: {r_opt}")
            continue

        reward = 1.0 if restaurant_name_slug in liked_slugs_set else -0.5

        # Ensure we're using the correct tags_set from the full restaurant object
        collected_experiences.append({'tags_set': set(r_opt.get('tags_set', [])), 'reward': reward})

    for exp in collected_experiences:
        state_mh = tags_to_multihot_dqn(exp['tags_set'])
        agent.remember(state_mh, exp['reward'])

    return collected_experiences

# --- DQN Training Function ---
def train_dqn_agent(agent, epoch_configs, all_experiences):
    """
    Trains the DQN agent and plots the training loss.
    """
    if not all_experiences:
        print("No experiences collected. Cannot train DQN.")
        return {}

    print(f"\nCollected {len(agent.replay_buffer)} individual restaurant experiences for DQN training.")

    batch_size_train = min(64, max(1, len(agent.replay_buffer) // 4 if len(agent.replay_buffer) > 0 else 1))
    all_loss_histories = {}
    print(f"\nTraining DQN with batch size: {batch_size_train}")

    for i, epochs_count in enumerate(epoch_configs):
        print(f"\n--- Training run {i+1} for {epochs_count} epochs ---")
        agent.reset_model_weights()
        loss_history = agent.replay_and_train(batch_size_train, epochs_count)
        all_loss_histories[epochs_count] = loss_history
        if not loss_history:
            print(f"Training for {epochs_count} epochs did not produce loss history.")

    # plt.figure(figsize=(10, 6))
    # plot_legend_added = False
    # for epochs_count, losses in all_loss_histories.items():
    #     if losses:
    #         plt.plot(losses, label=f'{epochs_count} Epochs Loss')
    #         plot_legend_added = True
    # if plot_legend_added:
    #     plt.title(f'DQN Training Loss')
    #     plt.xlabel('Epoch')
    #     plt.ylabel('Loss (MSE)')
    #     plt.legend()
    #     plt.grid(True)
    #     plt.show()
    # else:
    #     print("No training was performed or no loss data collected to plot.")
    return all_loss_histories

# --- 4. Create user.csv Function ---
def create_user_profile_csv(agent, aa_csv_tag_bool_columns, aa_csv_ordered_readable_tags, output_path='user.csv'):
    """
    Generates a user profile CSV based on the learned tag weights from the DQN agent.
    """
    print(f"\n--- Generating '{output_path}' with learned preference weights ---")
    learned_tag_weights_dict = agent.get_tag_weights()

    if not learned_tag_weights_dict or not any(learned_tag_weights_dict.values()):
        print("DQN did not learn significant weights. Cannot create user.csv or run KNN.")
        return None

    user_profile_data = {}
    for col_name in aa_csv_tag_bool_columns:
        user_profile_data[col_name] = 0.0

    for bool_col_name, readable_tag_name in zip(aa_csv_tag_bool_columns, aa_csv_ordered_readable_tags):
        if readable_tag_name in learned_tag_weights_dict:
            user_profile_data[bool_col_name] = learned_tag_weights_dict[readable_tag_name]

    df_user = pd.DataFrame([user_profile_data], columns=aa_csv_tag_bool_columns)

    try:
        df_user.to_csv(output_path, index=False)
        print(f"'{output_path}' created successfully.")
        user_vector_knn = df_user[aa_csv_tag_bool_columns].values.flatten()
        return user_vector_knn
    except Exception as e:
        print(f"Error saving '{output_path}': {e}")
        return None

# --- New User-facing Functions ---
def start():
    """
    Initializes the system and returns 5 groups of 3 restaurant names (from the 'name' slug).
    """
    global global_df_aa, global_agent, global_aa_csv_tag_bool_columns, global_aa_csv_ordered_readable_tags, global_restaurant_features_knn
    global global_shown_in_session_urls, global_all_experiences_for_buffer, global_current_round_options

    restaurant_data_file = 'resources/restaurant_data_with_tags_sorted_one_hot.csv'
    num_clusters = 30
    num_groups = 5 # Number of groups you requested
    names_per_group = 3 # Names per group you requested
    num_total_restaurants_needed = num_groups * names_per_group # 5 * 3 = 15 restaurants

    # 1. Load and Prepare Data
    if global_df_aa is None:
        global_df_aa, global_aa_csv_tag_bool_columns, global_aa_csv_ordered_readable_tags, global_restaurant_features_knn = \
            load_and_prepare_data(restaurant_data_file)

    # 2. K-Means Clustering
    if 'cluster' not in global_df_aa.columns:
        global_df_aa = perform_kmeans_clustering(global_df_aa, global_restaurant_features_knn, num_clusters)

    # Initialize DQN Agent
    if global_agent is None:
        global_agent = DQNAgent(state_size=NUM_TAGS_DQN)

    print("\nPreparing restaurant options for interaction...")

    # Get the restaurant options and store the full objects
    # Pass the total number of restaurants needed to the interaction round
    options_for_this_round_full, formatted_options_groups = start_interaction_round(
        global_df_aa, num_total_restaurants_needed, global_shown_in_session_urls
    )

    if not options_for_this_round_full:
        print(f"Could not find enough restaurants. Stopping.")

    # Store the full restaurant objects globally for the `train` function to use
    global_current_round_options = options_for_this_round_full

    # Format into the requested JSON structure
    output_json = {
        "restaurant_options": formatted_options_groups
    }
    return formatted_options_groups
    # return json.dumps(output_json, indent=4, ensure_ascii=False)

def train(liked_restaurant_name_slugs: list):
    """
    Processes user feedback based on a list of liked restaurant name slugs,
    trains the DQN agent, and generates the user.csv profile.

    Args:
        liked_restaurant_name_slugs (list): A list of individual restaurant name slugs (strings from the 'name' column)
                                            that the user liked from the options presented by the last `start()` call.
                                            Example: ['page', 'yuan-fang-guabao', 'good-crab-house']
    """
    global global_df_aa, global_agent, global_aa_csv_tag_bool_columns, global_aa_csv_ordered_readable_tags
    global global_all_experiences_for_buffer, global_current_round_options

    if global_agent is None or global_df_aa is None:
        print("System not initialized. Please call `start()` first.")
        return

    if not global_current_round_options:
        print("No restaurants were presented in the last round. Call `start()` first to get options.")
        return

    print("\nProcessing user feedback for training...")

    # Process the feedback using the simplified function
    current_round_experiences = process_user_feedback_simplified(
        global_agent,
        global_current_round_options, # Use the full details stored globally
        liked_restaurant_name_slugs # Pass the individual slugs directly for matching
    )
    global_all_experiences_for_buffer.extend(current_round_experiences)

    # Train DQN agent
    dqn_epoch_configs = [50]
    train_dqn_agent(global_agent, dqn_epoch_configs, global_all_experiences_for_buffer)

    # Create user.csv with learned preference weights
    user_profile_output_file = 'user.csv'
    user_vector = create_user_profile_csv(global_agent, global_aa_csv_tag_bool_columns, global_aa_csv_ordered_readable_tags, user_profile_output_file)

    if user_vector is not None:
        print("\nUser Profile Vector (for KNN):")
        print(user_vector)
    else:
        print("\nFailed to generate user profile vector.")

# --- Initial setup for the environment ---
# if __name__ == "__main__":
#     print("System ready. Call `start()` to get restaurant options and `train(liked_restaurant_name_slugs)` to train the model.")

#     # --- Example Usage ---
#     print("\n--- Step 1: Get Restaurant Options ---")
#     options_output_json = start()



#     print(options_output_json)

#     # Parse the output to get the name slugs for simulation
#     options_data = json.loads(options_output_json)
#     restaurant_groups = options_data['restaurant_options']

#     # Extract all individual name slugs from the groups for simulation
#     all_presented_slugs = []
#     for group in restaurant_groups:
#         for key in ['name1', 'name2', 'name3']:
#             if key in group:
#                 all_presented_slugs.append(group[key])

#     # Simulate user liking some of the presented individual names
#     # Let's say the user liked 'page', 'yuan-fang-guabao', and the first name in the third group



#     simulated_liked_slugs = ["old-new-taiwanese-cuisine-jiuru-2nd-road", "crab-s-house", "liang-liang-table", "lo-cheng-migao", "tu-pang" ]
#     # if all_presented_slugs:
#     #     simulated_liked_slugs.append(all_presented_slugs[0]) # Like the very first one
#     # if len(all_presented_slugs) > 1:
#     #     simulated_liked_slugs.append(all_presented_slugs[1]) # Like the second one
#     # if len(all_presented_slugs) > 7: # Picking one from the third group (index 6, 7, 8)
#     #     simulated_liked_slugs.append(all_presented_slugs[6])



#     print(f"\n--- Step 2: Simulate User Feedback (Liked slugs: {simulated_liked_slugs}) ---")
#     train(simulated_liked_slugs)





import pandas as pd
import numpy as np
import os
from sklearn.neighbors import NearestNeighbors
import json

# --- Configuration and Data Loading (unchanged) ---
USER_CSV_PATH = 'user.csv'

DEFAULT_TAG_HEADER_STR = "種類_中,種類_日,種類_法,種類_泰,種類_美,種類_西,種類_韓,類型_咖啡,類型_地方,類型_小吃,類型_居酒,類型_火鍋,類型_甜點,類型_聚餐,類型_茶館,類型_酒吧,類型_餐酒,氛圍_安靜,氛圍_家庭,氛圍_時尚,氛圍_浪漫,氛圍_熱鬧,氛圍_約會,氛圍_聚餐,氛圍_舒適"
DEFAULT_VALUE_STR = "0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0"

SHORT_TAG_MAP = {
    "中": "種類_中", "日": "種類_日", "法": "種類_法", "泰": "種類_泰", "美": "種類_美", "西": "種類_西", "韓": "種類_韓",
    "咖啡": "類型_咖啡", "地方": "類型_地方", "小吃": "類型_小吃", "居酒": "類型_居酒", "火鍋": "類型_火鍋",
    "甜點": "類型_甜點", "聚餐": "類型_聚餐", "茶館": "類型_茶館", "酒吧": "類型_酒吧", "餐酒": "類型_餐酒",
    "安靜": "氛圍_安靜", "家庭": "氛圍_家庭", "時尚": "氛圍_時尚", "浪漫": "氛圍_浪漫", "熱鬧": "氛圍_熱鬧",
    "約會": "氛圍_約會", "舒適": "氛圍_舒適",
}

TAG_COLUMN_MAP = {tag: tag for tag in DEFAULT_TAG_HEADER_STR.split(',')}

df_aa = pd.read_csv('resources/restaurant_data_with_tags_sorted_one_hot.csv')

AA_CSV_TAG_BOOL_COLUMNS = [col for col in TAG_COLUMN_MAP.keys() if col in df_aa.columns]
AA_CSV_ORDERED_READABLE_TAGS = [TAG_COLUMN_MAP[col] for col in AA_CSV_TAG_BOOL_COLUMNS]
restaurant_features_knn = df_aa[AA_CSV_TAG_BOOL_COLUMNS].fillna(False).astype(float).values

# --- Functions (unchanged from previous version) ---
def create_default_user_df():
    """Creates a DataFrame from the default tag and value strings."""
    tags = [t.strip() for t in DEFAULT_TAG_HEADER_STR.split(',')]
    try:
        values = [float(v.strip()) for v in DEFAULT_VALUE_STR.split(',')]
    except ValueError:
        print("錯誤：預設數值字串中包含無法轉換為浮點數的內容。")
        return None

    if len(tags) != len(values):
        print("錯誤：預設標籤數量和預設數值數量不一致。")
        return None

    user_data = dict(zip(tags, values))
    return pd.DataFrame([user_data])

def generate_user_profile_programmatic(selected_tags_input_short):
    """
    Generates a user profile programmatically based on a list of selected SHORT tag names.
    This function now uses the SHORT_TAG_MAP to convert short inputs to full tag names.
    """
    df_user = None

    if os.path.exists(USER_CSV_PATH):
        try:
            df_user = pd.read_csv(USER_CSV_PATH)
            if not df_user.empty and len(df_user.columns) > 0:
                if len(df_user) > 1:
                    df_user = df_user.head(1).reset_index(drop=True)
            else:
                df_user = create_default_user_df()
        except pd.errors.EmptyDataError:
            df_user = create_default_user_df()
        except Exception as e:
            df_user = create_default_user_df()
    else:
        df_user = create_default_user_df()

    if df_user is None or df_user.empty:
        print("錯誤：無法載入或創建使用者設定檔 DataFrame。程式終止。")
        return None, None

    for col in AA_CSV_TAG_BOOL_COLUMNS:
        if col not in df_user.columns:
            df_user[col] = 0.0
    df_user = df_user[AA_CSV_TAG_BOOL_COLUMNS]

    df_user.iloc[0] = 0.0 # Reset all preferences to 0

    if selected_tags_input_short:
        for short_tag in selected_tags_input_short:
            full_tag_name = SHORT_TAG_MAP.get(short_tag)
            if full_tag_name:
                if full_tag_name in df_user.columns:
                    df_user.loc[0, full_tag_name] = 1.0
                else:
                    print(f"警告：選定的標籤 '{full_tag_name}' (來自短標籤 '{short_tag}') 不存在於設定檔中，將被忽略。")
            else:
                print(f"警告：無法將短標籤 '{short_tag}' 對應到任何已知標籤，將被忽略。")

    user_vector_knn = df_user[AA_CSV_TAG_BOOL_COLUMNS].values.flatten()
    return df_user, user_vector_knn

def get_recommendations_json(selected_tags_for_user_profile_short):
    """
    Generates restaurant recommendations based on selected (short) tags and returns them as JSON.
    This version returns an array of strings (restaurant names).
    """
    df_updated_user, user_vector = generate_user_profile_programmatic(selected_tags_for_user_profile_short)

    if df_updated_user is None or user_vector is None:
        print("使用者設定檔生成或更新失敗。無法提供推薦。")
        return json.dumps({"error": "Failed to generate user profile."})

    N_NEIGHBORS_TO_FIND = 20
    N_RANDOM_TO_SHOW = 10

    if N_NEIGHBORS_TO_FIND > len(df_aa):
        N_NEIGHBORS_TO_FIND = len(df_aa)

    if restaurant_features_knn.shape[0] == 0:
        print("No restaurant features available for KNN. Exiting.")
        return json.dumps({"error": "No restaurant features for KNN."})

    if N_NEIGHBORS_TO_FIND == 0 and len(df_aa) > 0:
        N_NEIGHBORS_TO_FIND = 1
    elif N_NEIGHBORS_TO_FIND == 0 and len(df_aa) == 0:
        print("No restaurants and no neighbors to find. Exiting.")
        return json.dumps({"error": "No restaurants to recommend."})

    knn_model = NearestNeighbors(n_neighbors=N_NEIGHBORS_TO_FIND, metric='cosine')
    knn_model.fit(restaurant_features_knn)

    if user_vector.ndim == 1:
        user_vector_reshaped = user_vector.reshape(1, -1)
    else:
        user_vector_reshaped = user_vector

    distances_all_neighbors, indices_all_neighbors = knn_model.kneighbors(user_vector_reshaped)

    # If there are no neighbors found (e.g., if N_NEIGHBORS_TO_FIND is 0 or less than 1)
    if len(indices_all_neighbors[0]) == 0:
        return json.dumps({"message": "No similar restaurants found based on current criteria."})

    indices_for_user = indices_all_neighbors[0]

    similar_restaurants_df = df_aa.iloc[indices_for_user].copy()

    if len(similar_restaurants_df) == 0:
        return json.dumps({"message": "No similar restaurants found."})

    if len(similar_restaurants_df) < N_RANDOM_TO_SHOW:
        restaurants_to_display_df = similar_restaurants_df
    else:
        restaurants_to_display_df = similar_restaurants_df.sample(n=N_RANDOM_TO_SHOW)

    # Build a list of just the 'name' (Chinese name) strings
    recommended_names = [row_data['name'] for _, row_data in restaurants_to_display_df.iterrows()]

    return json.dumps(recommended_names, ensure_ascii=False, indent=2) # Output list of strings

# --- Main execution block for simulation ---
# if __name__ == "__main__":
#     user_selected_tags_for_simulation = ["美", "浪漫"]

#     print(f"模擬使用者選擇的短標籤: {user_selected_tags_for_simulation}")
#     json_output = get_recommendations_json(user_selected_tags_for_simulation)
#     print("\n--- 推薦餐廳 (JSON 格式) ---")
#     print(json_output)